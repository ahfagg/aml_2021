{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Andrew H. Fagg\n",
    "'''\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "tf_tools = \"../../../../../tf_tools/\"\n",
    "#sys.path.append(tf_tools + \"metrics\")\n",
    "#sys.path.append(tf_tools + \"networks\")\n",
    "sys.path.append(tf_tools + \"experiment_control\")\n",
    "\n",
    "#from job_control import *\n",
    "import argparse\n",
    "import pickle\n",
    "import random\n",
    "from chesapeake_data import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Concatenate, UpSampling2D, Add\n",
    "from tensorflow.keras.layers import Convolution2D, Dense, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "#################################################################\n",
    "# Default plotting parameters\n",
    "FIGURESIZE=(10,6)\n",
    "FONTSIZE=18\n",
    "\n",
    "plt.rcParams['figure.figsize'] = FIGURESIZE\n",
    "plt.rcParams['font.size'] = FONTSIZE\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n",
    "\n",
    "#################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(input_shape, nclasses, filters=[30,30],\n",
    "                   lambda_regularization=None, activation='elu'):\n",
    "    if lambda_regularization is not None:\n",
    "        lambda_regularization = keras.regularizers.l2(lambda_regularization)\n",
    "        \n",
    "    input_tensor = Input(shape=input_shape, name=\"input\")\n",
    "        \n",
    "    tensor = Convolution2D(filters[0],\n",
    "                          kernel_size=(3,3),\n",
    "                           padding='same', \n",
    "                          use_bias=True,\n",
    "                          kernel_initializer='random_uniform',\n",
    "                          bias_initializer='zeros',\n",
    "                          kernel_regularizer=lambda_regularization,\n",
    "                          activation=activation)(input_tensor)\n",
    "    \n",
    "    \n",
    "    # Fill in magic\n",
    "    \n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, \n",
    "                                    epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=opt,\n",
    "                 metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def training_set_generator_images(ins, outs, batch_size=10,\n",
    "                          input_name='input', \n",
    "                        output_name='output'):\n",
    "    '''\n",
    "    Generator for producing random minibatches of image training samples.\n",
    "    \n",
    "    @param ins Full set of training set inputs (examples x row x col x chan)\n",
    "    @param outs Corresponding set of sample (examples x nclasses)\n",
    "    @param batch_size Number of samples for each minibatch\n",
    "    @param input_name Name of the model layer that is used for the input of the model\n",
    "    @param output_name Name of the model layer that is used for the output of the model\n",
    "    '''\n",
    "    \n",
    "    while True:\n",
    "        # Randomly select a set of example indices\n",
    "        example_indices = random.choices(range(ins.shape[0]), k=batch_size)\n",
    "        \n",
    "        # The generator will produce a pair of return values: one for inputs and one for outputs\n",
    "        yield({input_name: ins[example_indices,:,:,:]},\n",
    "             {output_name: outs[example_indices,:,:]})\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_base = '/home/fagg/datasets/radiant_earth/pa/pa_1m_2013_extended-train_patches/'\n",
    "ins, mask, outs, weights = load_files_from_dir(file_base + \"/F0\", filt='-[01]?')\n",
    "class_hist, class_weights=compute_class_weights(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(ins.shape[1:4], nclasses=7)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = training_set_generator_images(ins, outs, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=generator, epochs=10, steps_per_epoch=2,\n",
    "                        use_multiprocessing=False, \n",
    "                        verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
